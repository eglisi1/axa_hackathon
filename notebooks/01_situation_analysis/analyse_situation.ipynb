{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'Completion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Hackathon\\axa_hackathon\\notebooks\\01_situation_analysis\\analyse_situation.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m OPENAI_API_KEY \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Initialize Langchain's OpenAI LLM with your API key passed inside model_kwargs\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(model_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mapi_key\u001b[39;49m\u001b[39m'\u001b[39;49m: OPENAI_API_KEY})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_accident_info_dict\u001b[39m(text):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Construct the prompt to instruct the language model to return a dictionary\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre a technical user, that gets a course of event for a traffic accident. There are two involved parties. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Hackathon\\hackathon\\lib\\site-packages\\langchain\\load\\serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Hackathon\\hackathon\\lib\\site-packages\\pydantic\\main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Hackathon\\hackathon\\lib\\site-packages\\pydantic\\main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Hackathon\\hackathon\\lib\\site-packages\\langchain\\llms\\openai.py:266\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     values[\u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\n\u001b[0;32m    267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    269\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import openai python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install openai`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'openai' has no attribute 'Completion'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can use os.getenv to access your variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize Langchain's OpenAI LLM with your API key passed inside model_kwargs\n",
    "llm = OpenAI(model_kwargs={'api_key': OPENAI_API_KEY})\n",
    "\n",
    "def get_accident_info_dict(text):\n",
    "    # Construct the prompt to instruct the language model to return a dictionary\n",
    "    prompt = f\"You're a technical user, that gets a course of event for a traffic accident. There are two involved parties. \\n\\n{text}\\n\\n\"\n",
    "    prompt += \"Create a dictionary with the following structure:\\n\"\n",
    "    prompt += \"{\\n\"\n",
    "    prompt += '    \"Beteiligter\": \"1\",\\n'\n",
    "    prompt += '    \"Fahrzeug\": \"\",\\n'\n",
    "    prompt += '    \"Behaviour step 1\": \"\",\\n'\n",
    "    prompt += '    \"Behaviour step 2\": \"\",\\n'\n",
    "    prompt += '    \"Behaviour step n\": \"\"\\n'\n",
    "    prompt += '    \"Beteiligter\": \"2\",\\n'\n",
    "    prompt += '    \"Fahrzeug\": \"\",\\n'\n",
    "    prompt += '    \"Behaviour step 1\": \"\",\\n'\n",
    "    prompt += '    \"Behaviour step 2\": \"\",\\n'\n",
    "    prompt += '    \"Behaviour step n\": \"\"\\n'\n",
    "    prompt += \"}\\n\\n\"\n",
    "    \n",
    "        # Use Langchain to send the prompt to the OpenAI API\n",
    "    response = llm.generate(prompt, max_tokens=150)\n",
    "    \n",
    "    print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Hackathon\\axa_hackathon\\notebooks\\01_situation_analysis\\analyse_situation.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pinecone_api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mpinecone_api_key\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m OPENAI_API_KEY \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     chunk_size \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     chunk_overlap  \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m explanation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLangchain ist eine innovative Bibliothek für Python, die es Entwicklern ermöglicht, Large Language Models (LLMs) wie GPT-3 einfach zu nutzen. Sie dient als Schnittstelle, die das Senden von Anfragen an diese Modelle vereinfacht und die Integration in Projekte erleichtert. Mit Langchain kann man die mächtigen Fähigkeiten der LLMs direkt nutzen, um Texte zu generieren, zu verstehen oder Fragen zu beantworten. Es unterstützt verschiedene Backend-Systeme und bietet Tools zur Verarbeitung und Handhabung der Antworten. Die Bibliothek ist besonders nützlich für Entwickler, die künstliche Intelligenz in ihre Anwendungen einbauen möchten, ohne sich um die Komplexität der direkten Interaktion mit Modellen wie GPT-3 kümmern zu müssen. Langchain abstrahiert die Komplexität und bietet eine benutzerfreundliche Oberfläche.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Hackathon/axa_hackathon/notebooks/01_situation_analysis/analyse_situation.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39mcreate_documents([explanation])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can use os.getenv to access your variables\n",
    "pinecone_api_key = os.getenv('pinecone_api_key')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 10,\n",
    ")\n",
    "\n",
    "explanation = \"Langchain ist eine innovative Bibliothek für Python, die es Entwicklern ermöglicht, Large Language Models (LLMs) wie GPT-3 einfach zu nutzen. Sie dient als Schnittstelle, die das Senden von Anfragen an diese Modelle vereinfacht und die Integration in Projekte erleichtert. Mit Langchain kann man die mächtigen Fähigkeiten der LLMs direkt nutzen, um Texte zu generieren, zu verstehen oder Fragen zu beantworten. Es unterstützt verschiedene Backend-Systeme und bietet Tools zur Verarbeitung und Handhabung der Antworten. Die Bibliothek ist besonders nützlich für Entwickler, die künstliche Intelligenz in ihre Anwendungen einbauen möchten, ohne sich um die Komplexität der direkten Interaktion mit Modellen wie GPT-3 kümmern zu müssen. Langchain abstrahiert die Komplexität und bietet eine benutzerfreundliche Oberfläche.\"\n",
    "\n",
    "texts = text_splitter.create_documents([explanation])\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY  # Replace with your actual OpenAI API key.\n",
    "\n",
    "# Assuming `texts` is a list of objects and each has a `page_content` attribute\n",
    "text_to_embed = texts[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
